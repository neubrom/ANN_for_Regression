{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Artificial Neural Network",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cbb7fRy-eyr",
    "colab_type": "text"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sNDnxE2-pwE",
    "colab_type": "text"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.7.0'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('Folds5x2_pp.xlsx')\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.96   41.76 1024.07   73.17]\n",
      " [  25.18   62.96 1020.04   59.08]\n",
      " [   5.11   39.4  1012.16   92.14]\n",
      " ...\n",
      " [  31.32   74.33 1012.92   36.48]\n",
      " [  24.48   69.45 1013.86   62.39]\n",
      " [  21.6    62.52 1017.23   67.87]]\n",
      "[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mSLlAT9_eyI",
    "colab_type": "text"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsBULd_f_wLY",
    "colab_type": "text"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 21:41:12.421423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-17 21:41:12.421461: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-17 21:41:12.421494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brom-G2): /proc/driver/nvidia/version does not exist\n",
      "2022-01-17 21:41:12.422834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ann = tf.ann = tf.keras.models.Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iitAFJS_ABUn",
    "colab_type": "text"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lb4kK_wAKbs",
    "colab_type": "text"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwMOmKb3AdBY",
    "colab_type": "text"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq7e4fF6A1yy",
    "colab_type": "text"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDeylAs2An25",
    "colab_type": "text"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjVuiybYOo7r",
    "colab_type": "text"
   },
   "source": [
    "### Training the ANN model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.1409\n",
      "Epoch 2/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7181\n",
      "Epoch 3/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5709\n",
      "Epoch 4/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6724\n",
      "Epoch 5/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.6098\n",
      "Epoch 6/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5712\n",
      "Epoch 7/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4919\n",
      "Epoch 8/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3864\n",
      "Epoch 9/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7335\n",
      "Epoch 10/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7969\n",
      "Epoch 11/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8085\n",
      "Epoch 12/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.9000\n",
      "Epoch 13/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7288\n",
      "Epoch 14/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5422\n",
      "Epoch 15/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3063\n",
      "Epoch 16/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4829\n",
      "Epoch 17/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4898\n",
      "Epoch 18/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6888\n",
      "Epoch 19/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2310\n",
      "Epoch 20/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7908\n",
      "Epoch 21/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.6376\n",
      "Epoch 22/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3528\n",
      "Epoch 23/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5369\n",
      "Epoch 24/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3712\n",
      "Epoch 25/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8436\n",
      "Epoch 26/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.1997\n",
      "Epoch 27/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.1861\n",
      "Epoch 28/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8046\n",
      "Epoch 29/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5248\n",
      "Epoch 30/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2879\n",
      "Epoch 31/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2722\n",
      "Epoch 32/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.3679\n",
      "Epoch 33/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7713\n",
      "Epoch 34/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2495\n",
      "Epoch 35/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8315\n",
      "Epoch 36/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4988\n",
      "Epoch 37/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8709\n",
      "Epoch 38/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2756\n",
      "Epoch 39/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3244\n",
      "Epoch 40/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.9478\n",
      "Epoch 41/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3794\n",
      "Epoch 42/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2585\n",
      "Epoch 43/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2674\n",
      "Epoch 44/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7512\n",
      "Epoch 45/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8239\n",
      "Epoch 46/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4743\n",
      "Epoch 47/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4478\n",
      "Epoch 48/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4776\n",
      "Epoch 49/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4592\n",
      "Epoch 50/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4623\n",
      "Epoch 51/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4792\n",
      "Epoch 52/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3582\n",
      "Epoch 53/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3898\n",
      "Epoch 54/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3249\n",
      "Epoch 55/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7066\n",
      "Epoch 56/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4832\n",
      "Epoch 57/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4947\n",
      "Epoch 58/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.3749\n",
      "Epoch 59/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.5805\n",
      "Epoch 60/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.6597\n",
      "Epoch 61/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.9844\n",
      "Epoch 62/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2346\n",
      "Epoch 63/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.6132\n",
      "Epoch 64/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3056\n",
      "Epoch 65/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2549\n",
      "Epoch 66/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.6616\n",
      "Epoch 67/200\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 26.5146\n",
      "Epoch 68/200\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 27.0549\n",
      "Epoch 69/200\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 26.5464\n",
      "Epoch 70/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.3811\n",
      "Epoch 71/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4049\n",
      "Epoch 72/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3906\n",
      "Epoch 73/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3665\n",
      "Epoch 74/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.1950\n",
      "Epoch 75/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7241\n",
      "Epoch 76/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4159\n",
      "Epoch 77/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.2591\n",
      "Epoch 78/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7506\n",
      "Epoch 79/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8431\n",
      "Epoch 80/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3698\n",
      "Epoch 81/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2681\n",
      "Epoch 82/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4327\n",
      "Epoch 83/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3113\n",
      "Epoch 84/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3009\n",
      "Epoch 85/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5242\n",
      "Epoch 86/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8046\n",
      "Epoch 87/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2933\n",
      "Epoch 88/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5092\n",
      "Epoch 89/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7766\n",
      "Epoch 90/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3059\n",
      "Epoch 91/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5866\n",
      "Epoch 92/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.5330\n",
      "Epoch 93/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.5779\n",
      "Epoch 94/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3841\n",
      "Epoch 95/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3739\n",
      "Epoch 96/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.5598\n",
      "Epoch 97/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4870\n",
      "Epoch 98/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.3878\n",
      "Epoch 99/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.8748\n",
      "Epoch 100/200\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 26.2143\n",
      "Epoch 101/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4748\n",
      "Epoch 102/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7027\n",
      "Epoch 103/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4082\n",
      "Epoch 104/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.2875\n",
      "Epoch 105/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.2011\n",
      "Epoch 106/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3460\n",
      "Epoch 107/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.3404\n",
      "Epoch 108/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4593\n",
      "Epoch 109/200\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 26.8788\n",
      "Epoch 110/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.6152\n",
      "Epoch 111/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4056\n",
      "Epoch 112/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5115\n",
      "Epoch 113/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.1029\n",
      "Epoch 114/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3763\n",
      "Epoch 115/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.1976\n",
      "Epoch 116/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5850\n",
      "Epoch 117/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.2811\n",
      "Epoch 118/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4956\n",
      "Epoch 119/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6644\n",
      "Epoch 120/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4535\n",
      "Epoch 121/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3538\n",
      "Epoch 122/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4869\n",
      "Epoch 123/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2904\n",
      "Epoch 124/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3602\n",
      "Epoch 125/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2923\n",
      "Epoch 126/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3181\n",
      "Epoch 127/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4213\n",
      "Epoch 128/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4704\n",
      "Epoch 129/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5524\n",
      "Epoch 130/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8194\n",
      "Epoch 131/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.3187\n",
      "Epoch 132/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4883\n",
      "Epoch 133/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.8992\n",
      "Epoch 134/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.7904\n",
      "Epoch 135/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2879\n",
      "Epoch 136/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.0009\n",
      "Epoch 137/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4404\n",
      "Epoch 138/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2805\n",
      "Epoch 139/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5618\n",
      "Epoch 140/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8646\n",
      "Epoch 141/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4715\n",
      "Epoch 142/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4397\n",
      "Epoch 143/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3801\n",
      "Epoch 144/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8555\n",
      "Epoch 145/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.1351\n",
      "Epoch 146/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8463\n",
      "Epoch 147/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.6564\n",
      "Epoch 148/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5366\n",
      "Epoch 149/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.0508\n",
      "Epoch 150/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4730\n",
      "Epoch 151/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4715\n",
      "Epoch 152/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4944\n",
      "Epoch 153/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.2328\n",
      "Epoch 154/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.0911\n",
      "Epoch 155/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.0645\n",
      "Epoch 156/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5292\n",
      "Epoch 157/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6465\n",
      "Epoch 158/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6189\n",
      "Epoch 159/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6053\n",
      "Epoch 160/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4969\n",
      "Epoch 161/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.1576\n",
      "Epoch 162/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4004\n",
      "Epoch 163/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5094\n",
      "Epoch 164/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5698\n",
      "Epoch 165/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8996\n",
      "Epoch 166/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.9452\n",
      "Epoch 167/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3825\n",
      "Epoch 168/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7042\n",
      "Epoch 169/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.0347\n",
      "Epoch 170/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4507\n",
      "Epoch 171/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5911\n",
      "Epoch 172/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7486\n",
      "Epoch 173/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7067\n",
      "Epoch 174/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3466\n",
      "Epoch 175/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4897\n",
      "Epoch 176/200\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.4844\n",
      "Epoch 177/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4990\n",
      "Epoch 178/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.0159\n",
      "Epoch 179/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4548\n",
      "Epoch 180/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.8144\n",
      "Epoch 181/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.2954\n",
      "Epoch 182/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6724\n",
      "Epoch 183/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3249\n",
      "Epoch 184/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3854\n",
      "Epoch 185/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3359\n",
      "Epoch 186/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5707\n",
      "Epoch 187/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3379\n",
      "Epoch 188/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.3522\n",
      "Epoch 189/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.1717\n",
      "Epoch 190/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6923\n",
      "Epoch 191/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6152\n",
      "Epoch 192/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5471\n",
      "Epoch 193/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4815\n",
      "Epoch 194/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4455\n",
      "Epoch 195/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7723\n",
      "Epoch 196/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.6623\n",
      "Epoch 197/200\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.0837\n",
      "Epoch 198/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4201\n",
      "Epoch 199/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.4419\n",
      "Epoch 200/200\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.2925\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f5f6498edc0>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H0zKKNEBLD5",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predicting the results of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431.45 431.23]\n",
      " [462.38 460.01]\n",
      " [465.84 461.14]\n",
      " ...\n",
      " [473.12 473.26]\n",
      " [439.94 438.  ]\n",
      " [459.13 463.28]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}